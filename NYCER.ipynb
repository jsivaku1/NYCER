{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()\n",
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import HiveContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType,TimestampType,IntegerType\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import *\n",
    "from dateutil.parser import parse\n",
    "from pyspark.sql.functions import year, dayofmonth,dayofweek, month,unix_timestamp,to_timestamp\n",
    "from pyspark.sql import window, Window\n",
    "from pyspark.sql.window import Window\n",
    "import calendar\n",
    "from time import strftime\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf,col\n",
    "import pyspark.sql.functions as func\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    " .builder \\\n",
    " .master(\"local\") \\\n",
    " .appName(\"NYCER\") \\\n",
    " .config(\"spark.some.config.option\", \"some-value\") \\\n",
    " .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sqlContext.read.load('311_Service_Requests_from_2010_to_Present.csv',format='com.databricks.spark.csv', header='true', inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Unique Key: integer (nullable = true)\n",
      " |-- Created Date: string (nullable = true)\n",
      " |-- Closed Date: string (nullable = true)\n",
      " |-- Agency: string (nullable = true)\n",
      " |-- Agency Name: string (nullable = true)\n",
      " |-- Complaint Type: string (nullable = true)\n",
      " |-- Descriptor: string (nullable = true)\n",
      " |-- Location Type: string (nullable = true)\n",
      " |-- Incident Zip: string (nullable = true)\n",
      " |-- Incident Address: string (nullable = true)\n",
      " |-- Street Name: string (nullable = true)\n",
      " |-- Cross Street 1: string (nullable = true)\n",
      " |-- Cross Street 2: string (nullable = true)\n",
      " |-- Intersection Street 1: string (nullable = true)\n",
      " |-- Intersection Street 2: string (nullable = true)\n",
      " |-- Address Type: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Landmark: string (nullable = true)\n",
      " |-- Facility Type: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Due Date: string (nullable = true)\n",
      " |-- Resolution Description: string (nullable = true)\n",
      " |-- Resolution Action Updated Date: string (nullable = true)\n",
      " |-- Community Board: string (nullable = true)\n",
      " |-- BBL: string (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- X Coordinate (State Plane): long (nullable = true)\n",
      " |-- Y Coordinate (State Plane): string (nullable = true)\n",
      " |-- Open Data Channel Type: string (nullable = true)\n",
      " |-- Park Facility Name: string (nullable = true)\n",
      " |-- Park Borough: string (nullable = true)\n",
      " |-- Vehicle Type: string (nullable = true)\n",
      " |-- Taxi Company Borough: string (nullable = true)\n",
      " |-- Taxi Pick Up Location: string (nullable = true)\n",
      " |-- Bridge Highway Name: string (nullable = true)\n",
      " |-- Bridge Highway Direction: string (nullable = true)\n",
      " |-- Road Ramp: string (nullable = true)\n",
      " |-- Bridge Highway Segment: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata_rdd.persist(pyspark.StorageLevel.MEMORY_ONLY)\\ndata_rdd.getStorageLevel()\\nprint(data_rdd.getStorageLevel())\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rdd = data.rdd\n",
    "'''\n",
    "data_rdd.persist(pyspark.StorageLevel.MEMORY_ONLY)\n",
    "data_rdd.getStorageLevel()\n",
    "print(data_rdd.getStorageLevel())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_rdd.map(lambda d:(d[0],d[1],d[2],d[3],d[4],d[5],d[6],d[7],d[8],d[9],\n",
    "                        d[10],d[11],d[12],d[13],d[14],d[15],d[16],d[17],d[18],d[19],\n",
    "                        d[20],d[21],d[22],d[23],d[24],d[25],d[26],d[27],d[28],d[29],\n",
    "                        d[30],d[31],d[32],d[33],d[34],d[35],d[36],d[37],d[38],d[39],d[40]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnycer_df = sqlContext.createDataFrame(df,[\"unique_key\",\"created_date\",\"closed_date\",\"agency\",\"agency_name\",\"complaint_type\"\\n                                    ,\"descriptor\",\"status\",\"due_date\",\"resolution_action_updated_date\",\"resolution_description\",\\n                                    \"location_type\",\"incident_zip\",\"incident_address\",\"street_name\",\"crossstreet_1\",\"cross_street_2\"\\n                                    ,\"intersection_street_1\",\"intersection_street_2\",\"address_type\",\"city\",\"landmark\",\"facility_type\"\\n                                    ,\"community_board\",\"bbl\",\"borough\",\"x_coordinate\",\"y_coordinate\",\"open_data_channel_type\",\"latitude\"\\n                                    ,\"longitude\",\"location\",\"park_facility_name\",\"park_borough\",\"vehicle_type\",\"taxi_company_borough\"\\n                                    ,\"taxi_pick_up_location\",\"bridge_highway_name\",\"bridge_highway_direction\",\"road_ramp\",\"bridgehighway_segment\"])\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "nycer_df = sqlContext.createDataFrame(df,[\"unique_key\",\"created_date\",\"closed_date\",\"agency\",\"agency_name\",\"complaint_type\"\n",
    "                                    ,\"descriptor\",\"status\",\"due_date\",\"resolution_action_updated_date\",\"resolution_description\",\n",
    "                                    \"location_type\",\"incident_zip\",\"incident_address\",\"street_name\",\"crossstreet_1\",\"cross_street_2\"\n",
    "                                    ,\"intersection_street_1\",\"intersection_street_2\",\"address_type\",\"city\",\"landmark\",\"facility_type\"\n",
    "                                    ,\"community_board\",\"bbl\",\"borough\",\"x_coordinate\",\"y_coordinate\",\"open_data_channel_type\",\"latitude\"\n",
    "                                    ,\"longitude\",\"location\",\"park_facility_name\",\"park_borough\",\"vehicle_type\",\"taxi_company_borough\"\n",
    "                                    ,\"taxi_pick_up_location\",\"bridge_highway_name\",\"bridge_highway_direction\",\"road_ramp\",\"bridgehighway_segment\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField(\"created_date\", StringType(), True), \n",
    "                     StructField(\"closed_date\", StringType(), True),\n",
    "                     StructField(\"agency\", StringType(), True),\n",
    "                     StructField(\"complaint_type\", StringType(), True),\n",
    "                     StructField(\"location\", StringType(), True)])\n",
    "df = sqlContext.createDataFrame(data_rdd.map(lambda d:(d[1],d[2],d[3],d[5],d[25])), schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spark_shape(self):\n",
    "    return (self.count(),len(self.columns))\n",
    "pyspark.sql.dataframe.DataFrame.shape = spark_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.na.drop(subset=[\"closed_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19710524, 5)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_date: string (nullable = true)\n",
      " |-- closed_date: string (nullable = true)\n",
      " |-- agency: string (nullable = true)\n",
      " |-- complaint_type: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- parsed_created_date: string (nullable = true)\n",
      " |-- parsed_closed_date: string (nullable = true)\n",
      " |-- response_time: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"parsed_created_date\",f.from_unixtime(f.unix_timestamp(\"created_date\",'MM/dd/yyyy hh:mm:ss aa'),\n",
    "                                                    'MM/dd/yyyy HH:mm:ss'))\n",
    "df = df.withColumn(\"parsed_closed_date\",f.from_unixtime(f.unix_timestamp(\"closed_date\",'MM/dd/yyyy hh:mm:ss aa'),\n",
    "                                                    'MM/dd/yyyy HH:mm:ss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "timefmt='MM/dd/yyyy HH:mm:ss'\n",
    "timeDiff = (F.unix_timestamp(\"parsed_closed_date\",format=timefmt) - \n",
    "           F.unix_timestamp(\"parsed_created_date\",format=timefmt))/3600\n",
    "df = df.withColumn(\"response_time\",timeDiff.cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18849791, 8)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df = df.filter(col(\"year\") >= 2015)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.where(col('response_time')>=0)\n",
    "df = df.where((col('agency') == 'NYPD') |\n",
    "              (col('agency') == 'HPD') |\n",
    "              (col('agency') == 'DOT') |\n",
    "              (col('agency') == 'DSNY') | \n",
    "              (col('agency') == 'DEP') | \n",
    "              (col('agency') == 'DOB') | \n",
    "              (col('agency') == 'DPR') |\n",
    "              (col('agency') == 'DOHMH'))\n",
    "df = df.filter(~df[\"complaint_type\"].like(\"%bulky%\"))\n",
    "df = df.where((col('location') == 'BROOKLYN') |\n",
    "              (col('location') == 'QUEENS') |\n",
    "              (col('location') == 'MANHATTAN') |\n",
    "              (col('location') == 'BRONX') | \n",
    "              (col('location') == 'STATEN ISLAND'))\n",
    "'df = df.filter(col(\"year\") >= 2015)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(created_date='12/05/2014 12:00:00 AM', closed_date='12/13/2014 12:00:00 AM', agency='HPD', complaint_type='HEAT/HOT WATER', location='QUEENS', parsed_created_date='12/05/2014 00:00:00', parsed_closed_date='12/13/2014 00:00:00', response_time=192, year=None),\n",
       " Row(created_date='12/05/2014 12:00:00 AM', closed_date='12/10/2014 12:00:00 AM', agency='HPD', complaint_type='HEAT/HOT WATER', location='QUEENS', parsed_created_date='12/05/2014 00:00:00', parsed_closed_date='12/10/2014 00:00:00', response_time=120, year=None)]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agency = df.where(df.agency ==\"NYPD\")\n",
    "df_agency_rdd = df_agency.select(df.parsed_created_date,df.parsed_closed_date,df.agency,df.response_time).rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agency = df_agency_rdd.map(lambda d:(parse(d[0]),parse(d[1]),d[2],d[3])).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_1=datetime.datetime(2014, 8, 20, 20, 3, 57), _2=datetime.datetime(2014, 8, 20, 22, 32, 1), _3='NYPD', _4=2),\n",
       " Row(_1=datetime.datetime(2014, 8, 21, 0, 29, 37), _2=datetime.datetime(2014, 8, 21, 4, 32, 28), _3='NYPD', _4=4)]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agency.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcolnames = ['created_date','closed_date','agency','response_time']\n",
    "for c,n in zip(df_agency.columns,newcolnames):\n",
    "    df_agency=df_agency.withColumnRenamed(c,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agency = df_agency.filter(year(df_agency.created_date) >= 2015)\n",
    "df_agency = df_agency.filter(year(df_agency.created_date) <= 2018).orderBy(\"created_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(created_date=datetime.datetime(2015, 1, 1, 0, 0, 50), closed_date=datetime.datetime(2015, 1, 1, 2, 47, 50), agency='NYPD', response_time=2.783333333333333, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 1, 29), closed_date=datetime.datetime(2015, 1, 1, 2, 42, 22), agency='NYPD', response_time=2.681388888888889, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 1, 30), closed_date=datetime.datetime(2015, 1, 1, 0, 20, 33), agency='NYPD', response_time=0.3175, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 4, 28), closed_date=datetime.datetime(2015, 1, 1, 2, 25, 2), agency='NYPD', response_time=2.3427777777777776, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 4, 44), closed_date=datetime.datetime(2015, 1, 1, 10, 22, 31), agency='NYPD', response_time=10.296388888888888, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 4, 51), closed_date=datetime.datetime(2015, 1, 1, 1, 3, 7), agency='NYPD', response_time=0.9711111111111111, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 5, 5), closed_date=datetime.datetime(2015, 1, 1, 1, 22, 10), agency='NYPD', response_time=1.2847222222222223, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 5, 12), closed_date=datetime.datetime(2015, 1, 1, 1, 13, 15), agency='NYPD', response_time=1.1341666666666668, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 6, 2), closed_date=datetime.datetime(2015, 1, 1, 0, 43, 41), agency='NYPD', response_time=0.6275, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 6, 43), closed_date=datetime.datetime(2015, 1, 1, 6, 5, 18), agency='NYPD', response_time=5.976388888888889, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 7, 42), closed_date=datetime.datetime(2015, 1, 1, 0, 16, 24), agency='NYPD', response_time=0.145, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 8, 2), closed_date=datetime.datetime(2015, 1, 1, 1, 17, 43), agency='NYPD', response_time=1.1613888888888888, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 8, 34), closed_date=datetime.datetime(2015, 1, 1, 2, 42, 23), agency='NYPD', response_time=2.5636111111111113, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 9, 39), closed_date=datetime.datetime(2015, 1, 1, 1, 29, 36), agency='NYPD', response_time=1.3325, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 9, 40), closed_date=datetime.datetime(2015, 1, 1, 7, 38, 38), agency='NYPD', response_time=7.482777777777778, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 10, 44), closed_date=datetime.datetime(2015, 1, 1, 10, 30, 50), agency='NYPD', response_time=10.335, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 11, 14), closed_date=datetime.datetime(2015, 1, 1, 5, 2, 42), agency='NYPD', response_time=4.857777777777778, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 11, 33), closed_date=datetime.datetime(2015, 1, 1, 4, 38, 30), agency='NYPD', response_time=4.449166666666667, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 12, 47), closed_date=datetime.datetime(2015, 1, 1, 2, 58, 37), agency='NYPD', response_time=2.763888888888889, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 13, 15), closed_date=datetime.datetime(2015, 1, 1, 0, 19, 30), agency='NYPD', response_time=0.10416666666666667, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 13, 36), closed_date=datetime.datetime(2015, 1, 1, 6, 30, 39), agency='NYPD', response_time=6.284166666666667, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 14), closed_date=datetime.datetime(2015, 1, 1, 2, 21, 48), agency='NYPD', response_time=2.13, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 14, 37), closed_date=datetime.datetime(2015, 1, 1, 4, 48, 58), agency='NYPD', response_time=4.5725, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 14, 39), closed_date=datetime.datetime(2015, 1, 1, 0, 41, 29), agency='NYPD', response_time=0.44722222222222224, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 15, 33), closed_date=datetime.datetime(2015, 1, 1, 0, 56, 37), agency='NYPD', response_time=0.6844444444444444, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 15, 45), closed_date=datetime.datetime(2015, 1, 1, 2, 4, 54), agency='NYPD', response_time=1.8191666666666666, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 15, 50), closed_date=datetime.datetime(2015, 1, 1, 3, 35, 27), agency='NYPD', response_time=3.3269444444444445, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 15, 50), closed_date=datetime.datetime(2015, 1, 1, 0, 43, 41), agency='NYPD', response_time=0.46416666666666667, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 15, 57), closed_date=datetime.datetime(2015, 1, 1, 4, 52, 13), agency='NYPD', response_time=4.604444444444445, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 17, 27), closed_date=datetime.datetime(2015, 1, 1, 0, 36, 11), agency='NYPD', response_time=0.31222222222222223, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 17, 46), closed_date=datetime.datetime(2015, 1, 1, 0, 58, 47), agency='NYPD', response_time=0.6836111111111111, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 17, 47), closed_date=datetime.datetime(2015, 1, 1, 0, 51, 13), agency='NYPD', response_time=0.5572222222222222, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 17, 48), closed_date=datetime.datetime(2015, 1, 1, 3, 24, 48), agency='NYPD', response_time=3.1166666666666667, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 18, 49), closed_date=datetime.datetime(2015, 1, 1, 3, 17, 11), agency='NYPD', response_time=2.972777777777778, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 19, 9), closed_date=datetime.datetime(2015, 1, 1, 0, 55, 31), agency='NYPD', response_time=0.6061111111111112, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 19, 10), closed_date=datetime.datetime(2015, 1, 1, 0, 41, 30), agency='NYPD', response_time=0.37222222222222223, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 19, 20), closed_date=datetime.datetime(2015, 1, 1, 3, 17, 10), agency='NYPD', response_time=2.963888888888889, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 19, 22), closed_date=datetime.datetime(2015, 1, 1, 2, 41, 10), agency='NYPD', response_time=2.3633333333333333, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 20, 4), closed_date=datetime.datetime(2015, 1, 1, 9, 14, 17), agency='NYPD', response_time=8.903611111111111, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 20, 31), closed_date=datetime.datetime(2015, 1, 1, 10, 22, 32), agency='NYPD', response_time=10.033611111111112, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 22, 11), closed_date=datetime.datetime(2015, 1, 1, 1, 26, 24), agency='NYPD', response_time=1.0702777777777779, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 22, 27), closed_date=datetime.datetime(2015, 1, 1, 5, 16, 30), agency='NYPD', response_time=4.900833333333333, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 23, 47), closed_date=datetime.datetime(2015, 1, 1, 1, 22, 7), agency='NYPD', response_time=0.9722222222222222, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 23, 55), closed_date=datetime.datetime(2015, 1, 1, 2, 58, 38), agency='NYPD', response_time=2.578611111111111, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 24, 25), closed_date=datetime.datetime(2015, 1, 1, 0, 43, 38), agency='NYPD', response_time=0.3202777777777778, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 24, 37), closed_date=datetime.datetime(2015, 1, 1, 0, 44, 46), agency='NYPD', response_time=0.3358333333333333, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 24, 39), closed_date=datetime.datetime(2015, 1, 1, 2, 42, 24), agency='NYPD', response_time=2.2958333333333334, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 26, 5), closed_date=datetime.datetime(2015, 1, 1, 0, 42, 33), agency='NYPD', response_time=0.27444444444444444, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 27, 14), closed_date=datetime.datetime(2015, 1, 1, 1, 27, 28), agency='NYPD', response_time=1.0038888888888888, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 28, 11), closed_date=datetime.datetime(2015, 1, 1, 3, 14, 3), agency='NYPD', response_time=2.7644444444444445, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 28, 53), closed_date=datetime.datetime(2015, 1, 1, 3, 19, 25), agency='NYPD', response_time=2.8422222222222224, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 29, 19), closed_date=datetime.datetime(2015, 1, 1, 2, 27, 7), agency='NYPD', response_time=1.9633333333333334, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 29, 41), closed_date=datetime.datetime(2015, 1, 1, 3, 7, 21), agency='NYPD', response_time=2.6277777777777778, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 29, 52), closed_date=datetime.datetime(2015, 1, 1, 2, 21, 51), agency='NYPD', response_time=1.8663888888888889, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 29, 54), closed_date=datetime.datetime(2015, 1, 1, 1, 25, 19), agency='NYPD', response_time=0.9236111111111112, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 30, 18), closed_date=datetime.datetime(2015, 1, 1, 0, 43, 38), agency='NYPD', response_time=0.2222222222222222, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 30, 28), closed_date=datetime.datetime(2015, 1, 1, 4, 9, 35), agency='NYPD', response_time=3.6519444444444447, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 30, 29), closed_date=datetime.datetime(2015, 1, 1, 1, 2, 4), agency='NYPD', response_time=0.5263888888888889, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 30, 40), closed_date=datetime.datetime(2015, 1, 1, 1, 28, 33), agency='NYPD', response_time=0.9647222222222223, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 31, 16), closed_date=datetime.datetime(2015, 1, 1, 4, 11, 46), agency='NYPD', response_time=3.675, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 31, 21), closed_date=datetime.datetime(2015, 1, 1, 1, 17, 48), agency='NYPD', response_time=0.7741666666666667, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 31, 36), closed_date=datetime.datetime(2015, 1, 1, 1, 0, 53), agency='NYPD', response_time=0.4880555555555556, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 31, 58), closed_date=datetime.datetime(2015, 1, 1, 4, 42, 42), agency='NYPD', response_time=4.178888888888889, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 32, 5), closed_date=datetime.datetime(2015, 1, 1, 3, 41, 53), agency='NYPD', response_time=3.1633333333333336, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 32, 26), closed_date=datetime.datetime(2015, 1, 1, 2, 30, 18), agency='NYPD', response_time=1.9644444444444444, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 33, 7), closed_date=datetime.datetime(2015, 1, 1, 5, 8, 2), agency='NYPD', response_time=4.581944444444445, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 34, 40), closed_date=datetime.datetime(2015, 1, 1, 8, 11, 5), agency='NYPD', response_time=7.606944444444444, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 34, 55), closed_date=datetime.datetime(2015, 1, 1, 1, 17, 49), agency='NYPD', response_time=0.715, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 35, 50), closed_date=datetime.datetime(2015, 1, 1, 1, 41, 25), agency='NYPD', response_time=1.0930555555555554, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 35, 58), closed_date=datetime.datetime(2015, 1, 1, 4, 10, 39), agency='NYPD', response_time=3.5780555555555558, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 36, 5), closed_date=datetime.datetime(2015, 1, 1, 1, 24, 16), agency='NYPD', response_time=0.8030555555555555, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 37, 5), closed_date=datetime.datetime(2015, 1, 1, 1, 9, 6), agency='NYPD', response_time=0.5336111111111111, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 37, 9), closed_date=datetime.datetime(2015, 1, 1, 2, 42, 18), agency='NYPD', response_time=2.0858333333333334, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 37, 13), closed_date=datetime.datetime(2015, 1, 1, 2, 43, 29), agency='NYPD', response_time=2.1044444444444443, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 37, 20), closed_date=datetime.datetime(2015, 1, 1, 3, 9, 33), agency='NYPD', response_time=2.5369444444444444, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 38, 10), closed_date=datetime.datetime(2015, 1, 1, 0, 59, 50), agency='NYPD', response_time=0.3611111111111111, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 38, 17), closed_date=datetime.datetime(2015, 1, 1, 1, 22, 8), agency='NYPD', response_time=0.7308333333333333, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 38, 48), closed_date=datetime.datetime(2015, 1, 1, 2, 43, 30), agency='NYPD', response_time=2.078333333333333, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 38, 56), closed_date=datetime.datetime(2015, 1, 1, 3, 14, 2), agency='NYPD', response_time=2.585, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 39, 2), closed_date=datetime.datetime(2015, 1, 1, 2, 55, 24), agency='NYPD', response_time=2.272777777777778, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 39, 9), closed_date=datetime.datetime(2015, 1, 1, 4, 36, 20), agency='NYPD', response_time=3.9530555555555558, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 39, 47), closed_date=datetime.datetime(2015, 1, 1, 2, 41, 9), agency='NYPD', response_time=2.022777777777778, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 40, 20), closed_date=datetime.datetime(2015, 1, 1, 2, 28, 11), agency='NYPD', response_time=1.7975, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 41, 8), closed_date=datetime.datetime(2015, 1, 1, 1, 27, 26), agency='NYPD', response_time=0.7716666666666666, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 41, 18), closed_date=datetime.datetime(2015, 1, 1, 3, 20, 30), agency='NYPD', response_time=2.6533333333333333, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 41, 34), closed_date=datetime.datetime(2015, 1, 1, 0, 49, 7), agency='NYPD', response_time=0.12583333333333332, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 41, 42), closed_date=datetime.datetime(2015, 1, 1, 0, 46, 54), agency='NYPD', response_time=0.08666666666666667, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 41, 51), closed_date=datetime.datetime(2015, 1, 1, 4, 11, 45), agency='NYPD', response_time=3.4983333333333335, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 42, 34), closed_date=datetime.datetime(2015, 1, 1, 5, 17, 34), agency='NYPD', response_time=4.583333333333333, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 42, 39), closed_date=datetime.datetime(2015, 1, 1, 4, 46, 50), agency='NYPD', response_time=4.0697222222222225, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 42, 58), closed_date=datetime.datetime(2015, 1, 1, 4, 37, 26), agency='NYPD', response_time=3.9077777777777776, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 43, 40), closed_date=datetime.datetime(2015, 1, 1, 1, 33, 55), agency='NYPD', response_time=0.8375, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 43, 43), closed_date=datetime.datetime(2015, 1, 1, 1, 27, 29), agency='NYPD', response_time=0.7294444444444445, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 44, 25), closed_date=datetime.datetime(2015, 1, 1, 1, 23, 13), agency='NYPD', response_time=0.6466666666666666, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 44, 30), closed_date=datetime.datetime(2015, 1, 1, 1, 27, 29), agency='NYPD', response_time=0.7163888888888889, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 44, 46), closed_date=datetime.datetime(2015, 1, 1, 10, 22, 32), agency='NYPD', response_time=9.629444444444445, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 44, 49), closed_date=datetime.datetime(2015, 1, 1, 5, 27, 7), agency='NYPD', response_time=4.705, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 45, 40), closed_date=datetime.datetime(2015, 1, 1, 10, 7, 52), agency='NYPD', response_time=9.37, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 45, 43), closed_date=datetime.datetime(2015, 1, 1, 0, 56, 35), agency='NYPD', response_time=0.1811111111111111, created_dt=datetime.date(2015, 1, 1), DayofWeek=5),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 45, 47), closed_date=datetime.datetime(2015, 1, 1, 3, 10, 39), agency='NYPD', response_time=2.4144444444444444, created_dt=datetime.date(2015, 1, 1), DayofWeek=5)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_date: timestamp (nullable = true)\n",
      " |-- closed_date: timestamp (nullable = true)\n",
      " |-- agency: string (nullable = true)\n",
      " |-- response_time: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_agency.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agency = df_agency.withColumn('created_dt',df_agency['created_date'].\n",
    "                                  cast('date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(created_date=datetime.datetime(2015, 1, 1, 0, 0, 50), closed_date=datetime.datetime(2015, 1, 1, 2, 47, 50), agency='NYPD', response_time=2, created_dt=datetime.date(2015, 1, 1)),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 1, 29), closed_date=datetime.datetime(2015, 1, 1, 2, 42, 22), agency='NYPD', response_time=2, created_dt=datetime.date(2015, 1, 1)),\n",
       " Row(created_date=datetime.datetime(2015, 1, 1, 0, 1, 30), closed_date=datetime.datetime(2015, 1, 1, 0, 20, 33), agency='NYPD', response_time=0, created_dt=datetime.date(2015, 1, 1))]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agency.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 = Sunday, 2 = Monday, ..., 7 = Saturday).\n",
    "df_agency = df_agency.withColumn('DayofWeek', dayofweek(df_agency.created_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = df_agency.select(df_agency.created_dt).where(df_agency.DayofWeek == 1).orderBy(df_agency.created_dt).distinct()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = start_date.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_date = start_date.toDF().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-02-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-02-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-03-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015-03-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015-04-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2015-04-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2015-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2015-05-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2015-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2015-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2015-05-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2015-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2015-06-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015-06-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2015-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2015-07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2015-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2015-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2015-07-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2018-06-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2018-06-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2018-06-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2018-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2018-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2018-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2018-07-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2018-07-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2018-08-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2018-08-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2018-08-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2018-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2018-09-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2018-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2018-09-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2018-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2018-09-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2018-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2018-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2018-10-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2018-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2018-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2018-11-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2018-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2018-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2018-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2018-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2018-12-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2018-12-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2018-12-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     created_dt\n",
       "0    2015-01-04\n",
       "1    2015-01-11\n",
       "2    2015-01-18\n",
       "3    2015-01-25\n",
       "4    2015-02-01\n",
       "5    2015-02-08\n",
       "6    2015-02-15\n",
       "7    2015-02-22\n",
       "8    2015-03-01\n",
       "9    2015-03-08\n",
       "10   2015-03-15\n",
       "11   2015-03-22\n",
       "12   2015-03-29\n",
       "13   2015-04-05\n",
       "14   2015-04-12\n",
       "15   2015-04-19\n",
       "16   2015-04-26\n",
       "17   2015-05-03\n",
       "18   2015-05-10\n",
       "19   2015-05-17\n",
       "20   2015-05-24\n",
       "21   2015-05-31\n",
       "22   2015-06-07\n",
       "23   2015-06-14\n",
       "24   2015-06-21\n",
       "25   2015-06-28\n",
       "26   2015-07-05\n",
       "27   2015-07-12\n",
       "28   2015-07-19\n",
       "29   2015-07-26\n",
       "..          ...\n",
       "179  2018-06-10\n",
       "180  2018-06-17\n",
       "181  2018-06-24\n",
       "182  2018-07-01\n",
       "183  2018-07-08\n",
       "184  2018-07-15\n",
       "185  2018-07-22\n",
       "186  2018-07-29\n",
       "187  2018-08-05\n",
       "188  2018-08-12\n",
       "189  2018-08-19\n",
       "190  2018-08-26\n",
       "191  2018-09-02\n",
       "192  2018-09-09\n",
       "193  2018-09-16\n",
       "194  2018-09-23\n",
       "195  2018-09-30\n",
       "196  2018-10-07\n",
       "197  2018-10-14\n",
       "198  2018-10-21\n",
       "199  2018-10-28\n",
       "200  2018-11-04\n",
       "201  2018-11-11\n",
       "202  2018-11-18\n",
       "203  2018-11-25\n",
       "204  2018-12-02\n",
       "205  2018-12-09\n",
       "206  2018-12-16\n",
       "207  2018-12-23\n",
       "208  2018-12-30\n",
       "\n",
       "[209 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_dt\n",
       "0  2015-01-04\n",
       "1  2015-01-11"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = start_date.head(1)\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'func' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-462b68cdf27b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mudf_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mudf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloatType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'func' is not defined"
     ]
    }
   ],
   "source": [
    "def median(values_list):\n",
    "    med = np.median(values_list)\n",
    "    return float(med)\n",
    "udf_median = func.udf(median, FloatType())\n",
    "\n",
    "\n",
    "df_grouped = df_agency.groupby(\"created_dt\").agg(udf_median(func.collect_list(col('response_time'))).alias('response_time')).orderBy(\"created_dt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o369.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 17.0 failed 1 times, most recent failure: Lost task 1.0 in stage 17.0 (TID 1395, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 253, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 248, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 331, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 140, in dump_stream\n    for obj in iterator:\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 320, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 76, in <lambda>\n    return lambda *a: f(*a)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-31-462b68cdf27b>\", line 2, in median\nNameError: name 'np' is not defined\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:330)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:83)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:66)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:284)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.util.random.SamplingUtils$.reservoirSampleAndCount(SamplingUtils.scala:41)\n\tat org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:306)\n\tat org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:304)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n\tat org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:309)\n\tat org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.prepareShuffleDependency(ShuffleExchangeExec.scala:224)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:91)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:371)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:247)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:294)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3200)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3197)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3259)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3258)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3197)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 253, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 248, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 331, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 140, in dump_stream\n    for obj in iterator:\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 320, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 76, in <lambda>\n    return lambda *a: f(*a)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-31-462b68cdf27b>\", line 2, in median\nNameError: name 'np' is not defined\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:330)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:83)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:66)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:284)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.util.random.SamplingUtils$.reservoirSampleAndCount(SamplingUtils.scala:41)\n\tat org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:306)\n\tat org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:304)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-01616fa41517>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrouped_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_grouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1966\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_exception_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1968\u001b[0;31m             \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \"\"\"\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o369.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 17.0 failed 1 times, most recent failure: Lost task 1.0 in stage 17.0 (TID 1395, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 253, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 248, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 331, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 140, in dump_stream\n    for obj in iterator:\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 320, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 76, in <lambda>\n    return lambda *a: f(*a)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-31-462b68cdf27b>\", line 2, in median\nNameError: name 'np' is not defined\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:330)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:83)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:66)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:284)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.util.random.SamplingUtils$.reservoirSampleAndCount(SamplingUtils.scala:41)\n\tat org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:306)\n\tat org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:304)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n\tat org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:309)\n\tat org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.prepareShuffleDependency(ShuffleExchangeExec.scala:224)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:91)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:371)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:247)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:294)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3200)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3197)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3259)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3258)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3197)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 253, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 248, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 331, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 140, in dump_stream\n    for obj in iterator:\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 320, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 76, in <lambda>\n    return lambda *a: f(*a)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-31-462b68cdf27b>\", line 2, in median\nNameError: name 'np' is not defined\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:330)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:83)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:66)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:284)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.util.random.SamplingUtils$.reservoirSampleAndCount(SamplingUtils.scala:41)\n\tat org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:306)\n\tat org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:304)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "grouped_median = df_grouped.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = date['created_dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agency_filtered = df_agency.where((df_agency.created_dt >= date) & (df_agency.created_dt <= date + timedelta(days=21))).orderBy(\"created_dt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|created_dt|\n",
      "+----------+\n",
      "|2015-01-04|\n",
      "|2015-01-05|\n",
      "|2015-01-06|\n",
      "|2015-01-07|\n",
      "|2015-01-08|\n",
      "|2015-01-09|\n",
      "|2015-01-10|\n",
      "|2015-01-11|\n",
      "|2015-01-12|\n",
      "|2015-01-13|\n",
      "|2015-01-14|\n",
      "|2015-01-15|\n",
      "|2015-01-16|\n",
      "|2015-01-17|\n",
      "|2015-01-18|\n",
      "|2015-01-19|\n",
      "|2015-01-20|\n",
      "|2015-01-21|\n",
      "|2015-01-22|\n",
      "|2015-01-23|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_agency_filtered.select(df_agency_filtered.created_dt).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_agency_filtered.where((df_agency_filtered.created_dt >= date) \\\n",
    "                                 & (df_agency_filtered.created_dt <= date + timedelta(days=13))) \\\n",
    "                                .orderBy(\"created_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_agency_filtered.select(\"created_date\",\"closed_date\",\"agency\",\"created_dt\",\"DayofWeek\",\"response_time\"). \\\n",
    "                where(df_agency_filtered.created_dt > date + timedelta(days=13)).orderBy(\"created_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>agency</th>\n",
       "      <th>response_time</th>\n",
       "      <th>created_dt</th>\n",
       "      <th>DayofWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04 00:00:02</td>\n",
       "      <td>2015-01-04 08:22:30</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>8.374444</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-04 00:00:04</td>\n",
       "      <td>2015-01-04 02:37:01</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>2.615833</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-04 00:00:41</td>\n",
       "      <td>2015-01-04 03:23:30</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>3.380278</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04 00:01:01</td>\n",
       "      <td>2015-01-04 00:45:39</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>0.743889</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-04 00:01:29</td>\n",
       "      <td>2015-01-04 01:00:30</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>0.983611</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         created_date         closed_date agency  response_time  created_dt  \\\n",
       "0 2015-01-04 00:00:02 2015-01-04 08:22:30   NYPD       8.374444  2015-01-04   \n",
       "1 2015-01-04 00:00:04 2015-01-04 02:37:01   NYPD       2.615833  2015-01-04   \n",
       "2 2015-01-04 00:00:41 2015-01-04 03:23:30   NYPD       3.380278  2015-01-04   \n",
       "3 2015-01-04 00:01:01 2015-01-04 00:45:39   NYPD       0.743889  2015-01-04   \n",
       "4 2015-01-04 00:01:29 2015-01-04 01:00:30   NYPD       0.983611  2015-01-04   \n",
       "\n",
       "   DayofWeek  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>agency</th>\n",
       "      <th>created_dt</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-18 00:00:18</td>\n",
       "      <td>2015-01-18 10:25:02</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>1</td>\n",
       "      <td>10.412222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-18 00:00:34</td>\n",
       "      <td>2015-01-18 00:29:16</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.478333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-18 00:01:04</td>\n",
       "      <td>2015-01-18 05:37:28</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>1</td>\n",
       "      <td>5.606667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-18 00:01:06</td>\n",
       "      <td>2015-01-18 07:56:51</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>1</td>\n",
       "      <td>7.929167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-18 00:02:00</td>\n",
       "      <td>2015-01-18 02:56:13</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>1</td>\n",
       "      <td>2.903611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         created_date         closed_date agency  created_dt  DayofWeek  \\\n",
       "0 2015-01-18 00:00:18 2015-01-18 10:25:02   NYPD  2015-01-18          1   \n",
       "1 2015-01-18 00:00:34 2015-01-18 00:29:16   NYPD  2015-01-18          1   \n",
       "2 2015-01-18 00:01:04 2015-01-18 05:37:28   NYPD  2015-01-18          1   \n",
       "3 2015-01-18 00:01:06 2015-01-18 07:56:51   NYPD  2015-01-18          1   \n",
       "4 2015-01-18 00:02:00 2015-01-18 02:56:13   NYPD  2015-01-18          1   \n",
       "\n",
       "   response_time  \n",
       "0      10.412222  \n",
       "1       0.478333  \n",
       "2       5.606667  \n",
       "3       7.929167  \n",
       "4       2.903611  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_pickle('train.pkl')\n",
    "#to load the file back, use train = pd.read_pickle('train.pkl')\n",
    "test.to_pickle('test.pkl')\n",
    "#to load the file back, use test = pd.read_pickle('test.pkl')\n",
    "start_date.to_pickle('start_date.pkl')\n",
    "\n",
    "\n",
    "grouped_median.to_pickle('grouped_median.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.read_pickle('start_date.pkl')\n",
    "df_grouped = pd.read_pickle('grouped_median.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_train = train.groupby(train.created_dt).median()\n",
    "grouped_test = test.groupby(test.created_dt).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_dt\n",
       "2015-01-04    2.434583\n",
       "2015-01-05    2.867500\n",
       "2015-01-06    2.551389\n",
       "2015-01-07    2.573611\n",
       "2015-01-08    2.528889\n",
       "2015-01-09    2.703889\n",
       "2015-01-10    2.285556\n",
       "2015-01-11    2.309861\n",
       "2015-01-12    2.782083\n",
       "2015-01-13    2.415556\n",
       "2015-01-14    2.734444\n",
       "2015-01-15    2.726944\n",
       "2015-01-16    2.645694\n",
       "2015-01-17    2.250000\n",
       "Name: response_time, dtype: float64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_train['response_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_dt\n",
       "2015-01-18    2.197778\n",
       "2015-01-19    2.340556\n",
       "2015-01-20    2.506944\n",
       "2015-01-21    2.447778\n",
       "2015-01-22    2.466111\n",
       "2015-01-23    2.804306\n",
       "2015-01-24    2.449444\n",
       "2015-01-25    2.253333\n",
       "Name: response_time, dtype: float64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_test['response_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = grouped_test.index\n",
    "test_Y = grouped_test['response_time']\n",
    "\n",
    "\n",
    "\n",
    "test_Y = test_Y.values.reshape(-1, 1)\n",
    "test_X = test_X.values.reshape(-1, 1)\n",
    "test_X = test_X.astype('datetime64[D]').astype(float)\n",
    "\n",
    "train_X = grouped_train.index\n",
    "train_Y = grouped_train['response_time']\n",
    "\n",
    "train_X = train_X.values.reshape(-1, 1)\n",
    "train_Y = train_Y.values.reshape(-1, 1)\n",
    "train_X = train_X.astype('datetime64[D]').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.43458333],\n",
       "       [2.8675    ],\n",
       "       [2.55138889],\n",
       "       [2.57361111],\n",
       "       [2.52888889],\n",
       "       [2.70388889],\n",
       "       [2.28555556],\n",
       "       [2.30986111],\n",
       "       [2.78208333],\n",
       "       [2.41555556],\n",
       "       [2.73444444],\n",
       "       [2.72694444],\n",
       "       [2.64569444],\n",
       "       [2.25      ]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import numpy as np\n",
    "from sklearn import datasets,linear_model\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn import preprocessing\n",
    "from math import sqrt\n",
    "from statistics import mean \n",
    "import math\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pyplot' from 'matplotlib.pylab' (/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/pylab.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a2ed779b8173>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'pyplot' from 'matplotlib.pylab' (/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/pylab.py)"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams,pyplot\n",
    "rcParams['figure.figsize'] = 15, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21366706481182757"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.1, copy_X=True,fit_intercept=True, max_iter=1)\n",
    "lasso.fit(train_X,train_Y)\n",
    "pred = lasso.predict(test_X)\n",
    "sqrt(mean_squared_error(test_Y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14912281],\n",
       "       [0.00633639],\n",
       "       [0.08004935],\n",
       "       ...,\n",
       "       [0.03119485],\n",
       "       [0.01183033],\n",
       "       [0.07224365]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.51761447],\n",
       "       [2.51224878],\n",
       "       [2.50688309],\n",
       "       [2.5015174 ],\n",
       "       [2.49615171],\n",
       "       [2.49078602],\n",
       "       [2.48542033],\n",
       "       [2.48005464]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18926032823908623"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(train_X,train_Y)\n",
    "pred = lr.predict(test_X)\n",
    "sqrt(mean_squared_error(test_Y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import dataframe as ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_dt</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2.207500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2.552917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>2.665694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>2.434583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>2.867500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>2.551389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>2.573611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>2.528889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>2.703889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>2.285556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>2.309861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>2.782083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015-01-13</td>\n",
       "      <td>2.415555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015-01-14</td>\n",
       "      <td>2.734444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>2.726944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015-01-16</td>\n",
       "      <td>2.645694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2015-01-17</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>2.197778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2015-01-19</td>\n",
       "      <td>2.340556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2015-01-20</td>\n",
       "      <td>2.506944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2015-01-21</td>\n",
       "      <td>2.447778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2015-01-22</td>\n",
       "      <td>2.466111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2015-01-23</td>\n",
       "      <td>2.804306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2015-01-24</td>\n",
       "      <td>2.449445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>2.253333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2015-01-26</td>\n",
       "      <td>2.257361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2015-01-27</td>\n",
       "      <td>2.163611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>2.478055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2015-01-29</td>\n",
       "      <td>2.265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>2.537361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>2018-12-02</td>\n",
       "      <td>2.483056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>2018-12-03</td>\n",
       "      <td>2.846944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>2018-12-04</td>\n",
       "      <td>2.770833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>2018-12-05</td>\n",
       "      <td>2.678750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2018-12-06</td>\n",
       "      <td>2.783056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>2.636389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2018-12-08</td>\n",
       "      <td>2.609028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2018-12-09</td>\n",
       "      <td>2.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2018-12-10</td>\n",
       "      <td>2.897222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>2018-12-11</td>\n",
       "      <td>2.873472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>2018-12-12</td>\n",
       "      <td>2.571944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>2018-12-13</td>\n",
       "      <td>2.966250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>2018-12-14</td>\n",
       "      <td>3.031945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>2018-12-15</td>\n",
       "      <td>2.797361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>2018-12-16</td>\n",
       "      <td>2.690139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>2018-12-17</td>\n",
       "      <td>2.931806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>3.458750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>2018-12-19</td>\n",
       "      <td>2.833889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>2018-12-20</td>\n",
       "      <td>3.231111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>3.037778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>2018-12-22</td>\n",
       "      <td>2.755139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>2018-12-23</td>\n",
       "      <td>2.521389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>2018-12-24</td>\n",
       "      <td>2.827083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2018-12-25</td>\n",
       "      <td>2.721667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2018-12-26</td>\n",
       "      <td>2.741945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>2.906528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>2.735000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>2.616389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>2.546944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2.540694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1461 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      created_dt  response_time\n",
       "0     2015-01-01       2.207500\n",
       "1     2015-01-02       2.552917\n",
       "2     2015-01-03       2.665694\n",
       "3     2015-01-04       2.434583\n",
       "4     2015-01-05       2.867500\n",
       "5     2015-01-06       2.551389\n",
       "6     2015-01-07       2.573611\n",
       "7     2015-01-08       2.528889\n",
       "8     2015-01-09       2.703889\n",
       "9     2015-01-10       2.285556\n",
       "10    2015-01-11       2.309861\n",
       "11    2015-01-12       2.782083\n",
       "12    2015-01-13       2.415555\n",
       "13    2015-01-14       2.734444\n",
       "14    2015-01-15       2.726944\n",
       "15    2015-01-16       2.645694\n",
       "16    2015-01-17       2.250000\n",
       "17    2015-01-18       2.197778\n",
       "18    2015-01-19       2.340556\n",
       "19    2015-01-20       2.506944\n",
       "20    2015-01-21       2.447778\n",
       "21    2015-01-22       2.466111\n",
       "22    2015-01-23       2.804306\n",
       "23    2015-01-24       2.449445\n",
       "24    2015-01-25       2.253333\n",
       "25    2015-01-26       2.257361\n",
       "26    2015-01-27       2.163611\n",
       "27    2015-01-28       2.478055\n",
       "28    2015-01-29       2.265000\n",
       "29    2015-01-30       2.537361\n",
       "...          ...            ...\n",
       "1431  2018-12-02       2.483056\n",
       "1432  2018-12-03       2.846944\n",
       "1433  2018-12-04       2.770833\n",
       "1434  2018-12-05       2.678750\n",
       "1435  2018-12-06       2.783056\n",
       "1436  2018-12-07       2.636389\n",
       "1437  2018-12-08       2.609028\n",
       "1438  2018-12-09       2.510000\n",
       "1439  2018-12-10       2.897222\n",
       "1440  2018-12-11       2.873472\n",
       "1441  2018-12-12       2.571944\n",
       "1442  2018-12-13       2.966250\n",
       "1443  2018-12-14       3.031945\n",
       "1444  2018-12-15       2.797361\n",
       "1445  2018-12-16       2.690139\n",
       "1446  2018-12-17       2.931806\n",
       "1447  2018-12-18       3.458750\n",
       "1448  2018-12-19       2.833889\n",
       "1449  2018-12-20       3.231111\n",
       "1450  2018-12-21       3.037778\n",
       "1451  2018-12-22       2.755139\n",
       "1452  2018-12-23       2.521389\n",
       "1453  2018-12-24       2.827083\n",
       "1454  2018-12-25       2.721667\n",
       "1455  2018-12-26       2.741945\n",
       "1456  2018-12-27       2.906528\n",
       "1457  2018-12-28       2.735000\n",
       "1458  2018-12-29       2.616389\n",
       "1459  2018-12-30       2.546944\n",
       "1460  2018-12-31       2.540694\n",
       "\n",
       "[1461 rows x 2 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = ddf.from_pandas(df_grouped, npartitions=8)\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_date = pd.read_pickle('start_date.pkl')\n",
    "df_grouped = pd.read_pickle('grouped_median.pkl')\n",
    "decimals = 2\n",
    "df_grouped['response_time'] = df_grouped['response_time'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date.drop(start_date.tail(3).index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.3\n"
     ]
    }
   ],
   "source": [
    "RMSE = []\n",
    "for index,row in start_date.iterrows():\n",
    "    date = row['created_dt']\n",
    "    df_agency_filtered = df_grouped.loc[(df_grouped['created_dt'] >= date) & \\\n",
    "                                         (df_grouped['created_dt'] < date + timedelta(days=21))].sort_values('created_dt')\n",
    "    train = df_agency_filtered.loc[(df_agency_filtered['created_dt'] >= date) \\\n",
    "                                 & (df_agency_filtered['created_dt'] <= date + timedelta(days=13))] \\\n",
    "                                .sort_values('created_dt')\n",
    "    test = df_agency_filtered.loc[(df_agency_filtered['created_dt'] > date + timedelta(days=13)) \\\n",
    "                                  & (df_agency_filtered['created_dt'] < date + timedelta(days=21)) ].sort_values('created_dt')\n",
    "    test_X = test.index\n",
    "    test_Y = test['response_time']\n",
    "\n",
    "\n",
    "\n",
    "    test_Y = test_Y.values.reshape(-1, 1)\n",
    "    test_X = test_X.values.reshape(-1, 1)\n",
    "    test_X = test_X.astype('datetime64[D]').astype(float)\n",
    "\n",
    "    train_X = train.index\n",
    "    train_Y = train['response_time']\n",
    "\n",
    "    train_X = train_X.values.reshape(-1, 1)\n",
    "    train_Y = train_Y.values.reshape(-1, 1)\n",
    "    train_X = train_X.astype('datetime64[D]').astype(float)\n",
    "    \n",
    "    #lr = LinearRegression()\n",
    "    #lr.fit(train_X,train_Y)\n",
    "    #pred = lr.predict(test_X)\n",
    "    #pred = pred.round(2)\n",
    "    lasso = Lasso(alpha=0.1, copy_X=True,fit_intercept=True, max_iter=1)\n",
    "    lasso.fit(train_X,train_Y)\n",
    "    pred = lasso.predict(test_X)\n",
    "    pred = pred.round(2)\n",
    "    err = sqrt(mean_squared_error(test_Y, pred))\n",
    "    RMSE.append(err)\n",
    "print(\"RMSE:\",np.round(mean(RMSE),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_grouped.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_dt\n",
       "2015-01-04    2.43\n",
       "2015-01-05    2.87\n",
       "2015-01-06    2.55\n",
       "2015-01-07    2.57\n",
       "2015-01-08    2.53\n",
       "2015-01-09    2.70\n",
       "2015-01-10    2.29\n",
       "2015-01-11    2.31\n",
       "2015-01-12    2.78\n",
       "2015-01-13    2.42\n",
       "2015-01-14    2.73\n",
       "2015-01-15    2.73\n",
       "2015-01-16    2.65\n",
       "2015-01-17    2.25\n",
       "2015-01-18    2.20\n",
       "2015-01-19    2.34\n",
       "2015-01-20    2.51\n",
       "2015-01-21    2.45\n",
       "2015-01-22    2.47\n",
       "2015-01-23    2.80\n",
       "2015-01-24    2.45\n",
       "Name: response_time, dtype: float32"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA(0, 0, 0) MSE=0.037\n",
      "ARIMA(0, 0, 1) MSE=0.049\n",
      "ARIMA(0, 0, 2) MSE=0.058\n",
      "ARIMA(0, 1, 0) MSE=0.044\n",
      "ARIMA(0, 1, 1) MSE=0.044\n",
      "ARIMA(0, 1, 2) MSE=0.052\n",
      "ARIMA(0, 2, 0) MSE=0.122\n",
      "ARIMA(0, 2, 1) MSE=0.059\n",
      "ARIMA(1, 0, 0) MSE=0.049\n",
      "ARIMA(1, 1, 0) MSE=0.047\n",
      "ARIMA(1, 2, 0) MSE=0.103\n",
      "ARIMA(2, 0, 0) MSE=0.055\n",
      "ARIMA(2, 1, 0) MSE=0.055\n",
      "ARIMA(2, 2, 0) MSE=0.089\n",
      "ARIMA(4, 0, 0) MSE=0.059\n",
      "ARIMA(4, 1, 0) MSE=0.080\n",
      "ARIMA(4, 2, 0) MSE=0.115\n",
      "Best ARIMA(0, 0, 0) MSE=0.037\n"
     ]
    }
   ],
   "source": [
    "RMSE = []\n",
    "import warnings\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# evaluate an ARIMA model for a given order (p,d,q)\n",
    "def evaluate_arima_model(arima_order):\n",
    "    # prepare training dataset\n",
    "    for index,row in start_date.iterrows():\n",
    "        date = row['created_dt']\n",
    "        df_agency_filtered = df_grouped.loc[(df_grouped['created_dt'] >= date) & \\\n",
    "                                             (df_grouped['created_dt'] < date + timedelta(days=21))].sort_values('created_dt')\n",
    "        train = df_agency_filtered.loc[(df_agency_filtered['created_dt'] >= date) \\\n",
    "                                     & (df_agency_filtered['created_dt'] <= date + timedelta(days=13))] \\\n",
    "                                    .sort_values('created_dt')\n",
    "        test = df_agency_filtered.loc[(df_agency_filtered['created_dt'] > date + timedelta(days=13)) \\\n",
    "                                      & (df_agency_filtered['created_dt'] < date + timedelta(days=21)) ].sort_values('created_dt')\n",
    "        train = train.set_index('created_dt')\n",
    "        train = train.T.squeeze()\n",
    "\n",
    "        test = test.set_index('created_dt')\n",
    "        test = test.T.squeeze()\n",
    "        history = [x for x in train]\n",
    "        # make predictions\n",
    "        predictions = list()\n",
    "        for t in range(len(test)):\n",
    "            model = ARIMA(history, order=arima_order)\n",
    "            model_fit = model.fit(disp=0)\n",
    "            yhat = model_fit.forecast()[0]\n",
    "            predictions.append(yhat)\n",
    "            history.append(test[t])\n",
    "        # calculate out of sample error\n",
    "        error = mean_squared_error(test, predictions)\n",
    "        return error\n",
    "\n",
    "# evaluate combinations of p, d and q values for an ARIMA model\n",
    "def evaluate_models(p_values, d_values, q_values):\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    for p in p_values:\n",
    "        for d in d_values:\n",
    "            for q in q_values:\n",
    "                order = (p,d,q)\n",
    "                try:\n",
    "                    mse = evaluate_arima_model(order)\n",
    "                    if mse < best_score:\n",
    "                        best_score, best_cfg = mse, order\n",
    "                    print('ARIMA%s MSE=%.3f' % (order,mse))\n",
    "                except:\n",
    "                    continue\n",
    "    print('Best ARIMA%s MSE=%.3f' % (best_cfg, best_score))\n",
    "\n",
    "# load dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# evaluate parameters\n",
    "p_values = [0, 1, 2, 4, 6, 8, 10]\n",
    "d_values = range(0, 3)\n",
    "q_values = range(0, 3)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "evaluate_models(p_values, d_values, q_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.28\n"
     ]
    }
   ],
   "source": [
    "for index,row in start_date.iterrows():\n",
    "        date = row['created_dt']\n",
    "        df_agency_filtered = df_grouped.loc[(df_grouped['created_dt'] >= date) & \\\n",
    "                                             (df_grouped['created_dt'] < date + timedelta(days=21))].sort_values('created_dt')\n",
    "        train = df_agency_filtered.loc[(df_agency_filtered['created_dt'] >= date) \\\n",
    "                                     & (df_agency_filtered['created_dt'] <= date + timedelta(days=13))] \\\n",
    "                                    .sort_values('created_dt')\n",
    "        test = df_agency_filtered.loc[(df_agency_filtered['created_dt'] > date + timedelta(days=13)) \\\n",
    "                                      & (df_agency_filtered['created_dt'] < date + timedelta(days=21)) ].sort_values('created_dt')\n",
    "        train = train.set_index('created_dt')\n",
    "        train = train.T.squeeze()\n",
    "\n",
    "        test = test.set_index('created_dt')\n",
    "        test = test.T.squeeze()\n",
    "        history = [x for x in train]\n",
    "        # make predictions\n",
    "        predictions = list()\n",
    "        for t in range(len(test)):\n",
    "            model = ARIMA(history, order=(0,0,0))\n",
    "            model_fit = model.fit(disp=0)\n",
    "            yhat = model_fit.forecast()[0]\n",
    "            predictions.append(yhat)\n",
    "            history.append(test[t])\n",
    "        # calculate out of sample error\n",
    "        error = sqrt(mean_squared_error(test, predictions))\n",
    "        RMSE.append(error)\n",
    "\n",
    "print(\"RMSE:\",np.round(mean(RMSE),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
